# Story 2.3: ML Model Training Pipeline

## Status: Ready for Review

## Assigned To: Mario

## Story

**As a** data scientist,
**I want** three ML models trained to predict demand,
**so that** I can compare performance and use the best predictor.

## Acceptance Criteria

1. Training pipeline in `backend/src/ml/training.py`
2. **Linear Regression** trained as interpretable baseline
3. **Decision Tree** trained with `max_depth` tuning (grid search 3-10)
4. **Random Forest** (or XGBoost) trained with GridSearchCV for hyperparameters
5. All models predict demand given context features + price as input
6. Models evaluated with: R², MAE, RMSE on test set
7. Comparison table generated and logged
8. Models serialized to `backend/data/models/*.joblib`

## Tasks / Subtasks

- [x] Task 1: Create training pipeline structure (AC: 1)
  - [x] Create `backend/src/ml/training.py`
  - [x] Create `ModelTrainer` class
  - [x] Load training data from Story 2.2

- [x] Task 2: Implement Linear Regression (AC: 2)
  - [x] Train sklearn LinearRegression
  - [x] Extract coefficients for interpretability
  - [x] Evaluate on test set

- [x] Task 3: Implement Decision Tree (AC: 3)
  - [x] Train sklearn DecisionTreeRegressor
  - [x] GridSearchCV for max_depth in [3, 4, 5, 6, 7, 8, 9, 10]
  - [x] Log best parameters

- [x] Task 4: Implement XGBoost (AC: 4)
  - [x] Train XGBRegressor
  - [x] GridSearchCV for: max_depth, n_estimators, learning_rate
  - [x] Log best parameters and feature importance

- [x] Task 5: Create evaluation framework (AC: 6, 7)
  - [x] Calculate R², MAE, RMSE for each model
  - [x] Generate comparison table
  - [x] Log results using loguru
  - [x] Save metrics to JSON

- [x] Task 6: Serialize models (AC: 8)
  - [x] Save to `backend/data/models/linear_regression.joblib`
  - [x] Save to `backend/data/models/decision_tree.joblib`
  - [x] Save to `backend/data/models/xgboost.joblib`
  - [x] Save feature names and preprocessing info

- [x] Task 7: Create model manager (AC: 5)
  - [x] Create `backend/src/ml/model_manager.py`
  - [x] `ModelManager` class to load and serve models
  - [x] `predict(context, price, model_name)` method
  - [x] Support selecting model at runtime

- [x] Task 8: Write tests
  - [x] Test model training completes
  - [x] Test predictions in valid range
  - [x] Test model persistence

## Dev Notes

### Feature Set for Training
```python
features = [
    "number_of_riders",
    "number_of_drivers", 
    "supply_demand_ratio",
    "location_category_encoded",
    "customer_loyalty_status_encoded",
    "number_of_past_rides",
    "average_ratings",
    "time_of_booking_encoded",
    "vehicle_type_encoded",
    "expected_ride_duration",
    "historical_cost_of_ride",
    "segment_encoded",
    "price"  # The variable we're optimizing
]

target = "demand"
```

### Model Configurations
```python
# Linear Regression - baseline
linear_reg = LinearRegression()

# Decision Tree - tuned
dt_params = {"max_depth": [3, 4, 5, 6, 7, 8, 9, 10]}
decision_tree = GridSearchCV(
    DecisionTreeRegressor(random_state=42),
    dt_params,
    cv=5,
    scoring="neg_mean_squared_error"
)

# XGBoost - production model
xgb_params = {
    "max_depth": [3, 5, 7],
    "n_estimators": [50, 100, 200],
    "learning_rate": [0.01, 0.1, 0.2]
}
xgboost = GridSearchCV(
    XGBRegressor(random_state=42),
    xgb_params,
    cv=5,
    scoring="neg_mean_squared_error"
)
```

### ModelManager Interface
```python
class ModelManager:
    def __init__(self, models_dir: str = "data/models"):
        self.models = {}
        self._load_models()
    
    def predict(
        self, 
        context: MarketContext, 
        price: float,
        model_name: str = "xgboost"
    ) -> float:
        """Predict demand for context at given price"""
        
    def get_all_predictions(
        self,
        context: MarketContext,
        price: float
    ) -> dict[str, float]:
        """Get predictions from all models for comparison"""
```

### File Locations
- Training: `backend/src/ml/training.py`
- Model Manager: `backend/src/ml/model_manager.py`
- Models: `backend/data/models/*.joblib`
- Metrics: `backend/data/models/metrics.json`

### Testing

- Test file: `backend/tests/unit/test_ml/test_training.py`
- Test file: `backend/tests/unit/test_ml/test_model_manager.py`
- Test predictions are in [0, 1] range
- Test all three models can be loaded and predict

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2024-12-02 | 1.0 | Initial story creation | SM Agent |
| 2024-12-02 | 1.1 | Implemented ML training pipeline with 3 models, ModelManager, tests | Dev Agent (James) |

## Dev Agent Record

### Agent Model Used
Claude Opus 4 (via Cursor)

### Debug Log References
- `pytest tests/unit/test_ml/test_training.py tests/unit/test_ml/test_model_manager.py -v` → 30/30 passed
- `pytest tests/ -v` → 144/144 passed (full regression)
- Model training: XGBoost R²=0.9859, Decision Tree R²=0.8986, Linear Regression R²=0.5764

### Completion Notes List
- Created `ModelTrainer` class with `train_all()`, `save_models()`, `save_metrics()`, `log_comparison()` methods
- Implemented GridSearchCV for Decision Tree (max_depth) and XGBoost (max_depth, n_estimators, learning_rate)
- Created `ModelManager` singleton for runtime model serving with `predict()` and `get_all_predictions()` methods
- Added `predict_demand_curve()` for generating demand curves at multiple price points
- Fixed JSON serialization for numpy float32 types from XGBoost feature importance
- XGBoost is best performer with R²=0.9859 on test set (8000 train, 2000 test samples)

### File List
| File | Action |
|------|--------|
| `backend/src/ml/training.py` | Created |
| `backend/src/ml/model_manager.py` | Created |
| `backend/src/ml/__init__.py` | Modified (exports) |
| `backend/tests/unit/test_ml/test_training.py` | Created |
| `backend/tests/unit/test_ml/test_model_manager.py` | Created |
| `backend/data/models/linear_regression.joblib` | Created |
| `backend/data/models/decision_tree.joblib` | Created |
| `backend/data/models/xgboost.joblib` | Created |
| `backend/data/models/encoders.joblib` | Created |
| `backend/data/models/feature_info.json` | Created |
| `backend/data/models/metrics.json` | Created |

## QA Results

### Review Date: 2024-12-02

### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment

**Overall: Excellent** - Production-ready implementation with clean architecture and comprehensive coverage.

**Strengths Identified:**
- Clean separation of concerns (ModelTrainer for training, ModelManager for serving)
- Proper use of dataclasses for structured data (ModelMetrics, TrainingResult)
- Comprehensive type hints throughout
- Excellent error handling with RuntimeError for precondition violations
- Smart singleton pattern for ModelManager with lazy loading
- Graceful handling of unseen categorical values (returns -1 instead of crashing)
- Prediction clipping to [0, 1] ensures valid demand range
- Comprehensive logging with loguru for debugging and monitoring
- Proper numpy type conversion for JSON serialization (fixed float32 issue)

**Model Performance:**
| Model | R² | MAE | RMSE |
|-------|-----|-----|------|
| XGBoost | 0.9859 | 0.0130 | 0.0250 |
| Decision Tree | 0.8986 | 0.0463 | 0.0670 |
| Linear Regression | 0.5764 | 0.0988 | 0.1369 |

XGBoost correctly identified as best performer with optimal hyperparameters (learning_rate=0.1, max_depth=7, n_estimators=200).

### Refactoring Performed

None required - implementation is clean and production-ready.

### Compliance Check

- Coding Standards: ✅ Follows Python conventions, type hints, docstrings
- Project Structure: ✅ Files in correct locations per architecture
- Testing Strategy: ✅ Unit tests with proper isolation and fixtures
- All ACs Met: ✅ All 8 acceptance criteria fully implemented and tested

### Requirements Traceability

| AC | Requirement | Test(s) | Status |
|----|-------------|---------|--------|
| 1 | Training pipeline in training.py | `test_trainer_initialization`, `test_load_data` | ✅ |
| 2 | Linear Regression baseline | `test_train_linear_regression` | ✅ |
| 3 | Decision Tree with max_depth [3-10] | `test_train_decision_tree` | ✅ |
| 4 | XGBoost with GridSearchCV | `test_train_xgboost` | ✅ |
| 5 | Models predict demand | `test_predict_*` (4 tests in model_manager) | ✅ |
| 6 | R², MAE, RMSE evaluation | `test_model_metrics_*`, training tests | ✅ |
| 7 | Comparison table generated | `test_get_comparison_table` | ✅ |
| 8 | Models serialized to joblib | `test_save_models`, `test_save_metrics` | ✅ |

### Improvements Checklist

All items addressed by developer:

- [x] ModelTrainer class with train_all(), save_models(), save_metrics()
- [x] GridSearchCV for Decision Tree (max_depth) and XGBoost (3 params)
- [x] ModelManager singleton with lazy loading
- [x] predict(), get_all_predictions(), predict_demand_curve() methods
- [x] Unseen category handling with graceful degradation
- [x] JSON serialization fix for numpy float32 types
- [x] Comprehensive unit tests (30 tests total)
- [x] Full regression passing (144/144 tests)

### Security Review

**No concerns** - Internal ML pipeline with no user input exposure. Models and encoders are loaded from disk with proper path handling.

### Performance Considerations

**Optimized:**
- GridSearchCV uses `n_jobs=-1` for parallel cross-validation
- ModelManager implements singleton pattern to avoid repeated loading
- Lazy loading on first predict() call

### Files Modified During Review

None - no refactoring needed.

### Gate Status

Gate: **PASS** → `docs/qa/gates/2.3-ml-training-pipeline.yml`

### Recommended Status

✅ **Ready for Done** - All acceptance criteria met, comprehensive test coverage, excellent code quality.

