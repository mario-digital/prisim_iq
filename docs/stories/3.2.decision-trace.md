# Story 3.2: Decision Trace Generation

## Status: Draft

## Assigned To: Mario

## Story

**As a** pricing analyst,
**I want** a step-by-step trace of how the system arrived at a price,
**so that** I can audit decisions.

## Acceptance Criteria

1. Trace captures complete pipeline: Input → Segment → External Factors → Model Prediction → Optimization → Rules → Final Price
2. Each step includes: timestamp, duration (ms), input values, output values
3. Trace exportable as JSON (API response) and formatted text (for display)
4. Model agreement indicator: shows if all models agree within 10% or diverge
5. Trace stored for audit purposes (optional file logging)

## Tasks / Subtasks

- [ ] Task 1: Create decision trace module (AC: 1)
  - [ ] Create `backend/src/explainability/decision_trace.py`
  - [ ] Create `DecisionTracer` class
  - [ ] Define trace step structure

- [ ] Task 2: Implement step tracking (AC: 2)
  - [ ] Create `TraceStep` dataclass
  - [ ] Include timestamp, duration_ms, inputs, outputs
  - [ ] Use context manager or decorator pattern

- [ ] Task 3: Integrate with pricing pipeline (AC: 1)
  - [ ] Trace segment classification step
  - [ ] Trace external factors retrieval
  - [ ] Trace model prediction step
  - [ ] Trace optimization step
  - [ ] Trace rules application step

- [ ] Task 4: Calculate model agreement (AC: 4)
  - [ ] Get predictions from all 3 models
  - [ ] Calculate max deviation percentage
  - [ ] Agreement if all within 10%

- [ ] Task 5: Create export formats (AC: 3)
  - [ ] JSON format for API response
  - [ ] Formatted text for display
  - [ ] Include all steps and timing

- [ ] Task 6: Optional audit logging (AC: 5)
  - [ ] Log trace to file if configured
  - [ ] Include request ID for correlation
  - [ ] Configurable log level

- [ ] Task 7: Write tests
  - [ ] Test all steps captured
  - [ ] Test duration calculation
  - [ ] Test model agreement calculation

## Dev Notes

### TraceStep Schema
```python
class TraceStep(BaseModel):
    step_name: str  # "segment_classification"
    timestamp: datetime
    duration_ms: float
    inputs: dict[str, Any]
    outputs: dict[str, Any]
    status: Literal["success", "error", "skipped"]
    error_message: str | None = None

class DecisionTrace(BaseModel):
    trace_id: str  # UUID
    request_timestamp: datetime
    total_duration_ms: float
    steps: list[TraceStep]
    model_agreement: ModelAgreement
    final_result: dict[str, Any]
    
class ModelAgreement(BaseModel):
    models_compared: list[str]
    predictions: dict[str, float]
    max_deviation_percent: float
    is_agreement: bool  # True if all within 10%
    status: Literal["full_agreement", "partial_agreement", "divergent"]
```

### Decorator Pattern for Tracing
```python
from functools import wraps
import time

class DecisionTracer:
    def __init__(self):
        self.steps: list[TraceStep] = []
        self.trace_id = str(uuid.uuid4())
        self.start_time = datetime.now()
    
    def trace_step(self, step_name: str):
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                start = time.perf_counter()
                try:
                    result = func(*args, **kwargs)
                    duration = (time.perf_counter() - start) * 1000
                    self.steps.append(TraceStep(
                        step_name=step_name,
                        timestamp=datetime.now(),
                        duration_ms=duration,
                        inputs={"args": str(args)},
                        outputs={"result": str(result)},
                        status="success"
                    ))
                    return result
                except Exception as e:
                    duration = (time.perf_counter() - start) * 1000
                    self.steps.append(TraceStep(
                        step_name=step_name,
                        timestamp=datetime.now(),
                        duration_ms=duration,
                        inputs={"args": str(args)},
                        outputs={},
                        status="error",
                        error_message=str(e)
                    ))
                    raise
            return wrapper
        return decorator
```

### Pipeline Steps to Trace
1. `input_validation` - Validate MarketContext
2. `segment_classification` - Classify into segment
3. `external_factors` - Fetch weather/events/fuel
4. `demand_prediction` - ML model prediction
5. `price_optimization` - Find optimal price
6. `rules_application` - Apply business rules
7. `explanation_generation` - Generate explanations

### Formatted Text Output
```text
=== Decision Trace: abc-123-def ===
Request Time: 2024-12-02T10:15:30Z
Total Duration: 1,234ms

Step 1: Input Validation (15ms) ✓
  Input: MarketContext(location=Urban, vehicle=Premium, ...)
  Output: Valid

Step 2: Segment Classification (45ms) ✓
  Input: Processed features
  Output: Segment "Urban_Peak_Premium"

Step 3: External Factors (120ms) ✓
  Input: Location coordinates
  Output: Weather=rainy (+15%), Events=none

...

Model Agreement: FULL (max deviation 3.2%)
  - XGBoost: $42.50
  - Random Forest: $43.10
  - Linear Regression: $41.80

Final Price: $42.50
```

### Testing

- Test file: `backend/tests/unit/test_explainability/test_decision_trace.py`
- Test all 7 steps captured
- Test duration_ms > 0 for each step
- Test model agreement calculation

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2024-12-02 | 1.0 | Initial story creation | SM Agent |

## Dev Agent Record

### Agent Model Used
(To be filled by Dev Agent)

### Debug Log References
(To be filled by Dev Agent)

### Completion Notes List
(To be filled by Dev Agent)

### File List
(To be filled by Dev Agent)

## QA Results
(To be filled by QA Agent)

