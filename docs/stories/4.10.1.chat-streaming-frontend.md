# Story 4.10.1: Chat Streaming Frontend Integration

## Status: Draft

## Assigned To: Pending

## Story

**As a** pricing analyst,
**I want** to see AI responses appear token-by-token in real-time,
**so that** I have immediate feedback that the system is working and can read responses as they generate.

## Acceptance Criteria

1. Chat service updated to handle SSE streaming from `/api/v1/chat`
2. Messages render progressively as tokens arrive (typewriter effect)
3. Tool call indicators shown when agent invokes backend tools
4. Typing indicator replaced by actual streaming content
5. Error handling for stream interruptions with retry option
6. Smooth transition from streaming to complete message
7. Non-streaming fallback if SSE connection fails
8. Keepalive-safe: ignore empty keepalive payloads (e.g., `{}`) and SSE comment lines (`: keepalive`)
9. Orchestrator-ready: pass through `plan=true` (and optional `model=`) and render tool/worker progress unobtrusively

## Tasks / Subtasks

- [ ] Task 1: Update chat service for SSE (AC: 1)
  - [ ] Modify `frontend/src/services/chatService.ts`
  - [ ] Implement `EventSource` or `fetch` with ReadableStream
  - [ ] Parse SSE `data:` events
  - [ ] Handle connection lifecycle (open, message, error, close)

- [ ] Task 2: Create streaming message state (AC: 2, 6)
  - [ ] Update `frontend/src/stores/chatStore.ts`
  - [ ] Add `streamingMessage: string | null` state
  - [ ] Add `appendToStreaming(token: string)` action
  - [ ] Add `finalizeStreaming()` action to convert to complete message

- [ ] Task 3: Update AIMessage for streaming (AC: 2)
  - [ ] Modify `frontend/src/components/chat/AIMessage.tsx`
  - [ ] Accept `isStreaming` prop
  - [ ] Render partial content with cursor indicator
  - [ ] Smooth CSS transition for new tokens

- [ ] Task 4: Create tool call indicator (AC: 3)
  - [ ] Create `frontend/src/components/chat/ToolCallIndicator.tsx`
  - [ ] Display tool name being called (e.g., "üîß Calling optimize_price...")
  - [ ] Animate while tool executes
  - [ ] Collapse/fade when tool completes

- [ ] Task 5: Update ChatPanel orchestration (AC: 2, 4, 6)
  - [ ] Modify `frontend/src/components/chat/ChatPanel.tsx`
  - [ ] Replace typing indicator with streaming message when tokens arrive
  - [ ] Show ToolCallIndicator during tool execution
  - [ ] Handle stream completion

- [ ] Task 6: Implement error handling (AC: 5, 7)
  - [ ] Detect stream disconnection
  - [ ] Show "Connection lost" message with retry button
  - [ ] Implement retry logic with exponential backoff
  - [ ] Fall back to non-streaming if SSE fails 3 times

- [ ] Task 7: Add streaming visual polish (AC: 2, 6)
  - [ ] Add blinking cursor at end of streaming text
  - [ ] Smooth scroll as content grows
  - [ ] Fade out cursor on completion
  - [ ] Match typing speed to token arrival

- [ ] Task 8: Write tests
  - [ ] Test SSE parsing
  - [ ] Test progressive rendering
  - [ ] Test error recovery
  - [ ] Test store state transitions

## Dev Notes

### SSE Event Format (Backend v1)
```
data: {"token": "The ", "done": false}

data: {"token": "optimal ", "done": false}

data: {"tool_call": "optimize_price", "done": false}

data: {"token": "price is $24.50", "done": false}

data: {"message": "...", "tools_used": ["optimize_price"], "done": true}

// Optional keepalive (comment line) when enabled
: keepalive

// Some environments may emit an empty data object as keepalive
data: {}
```

### Updated Chat Service (POST + streamed body)
```typescript
// services/chatService.ts
export type ChatStreamEvent =
  | { token: string; done: false }
  | { tool_call: string; done: false }
  | { message: string; tools_used?: string[]; done: true }
  | { error: string; done: true }
  | Record<string, never>; // keepalive `{}` (ignored)

interface StreamOptions {
  plan?: boolean;         // orchestrator path
  keepalive?: boolean;    // enable backend heartbeats
  interval?: number;      // keepalive seconds
  model?: string;         // optional reporter model hint
  signal?: AbortSignal;   // for cancel
}

export async function* streamMessage(
  message: string,
  context: MarketContext,
  opts: StreamOptions = {}
): AsyncGenerator<ChatStreamEvent> {
  const q = new URLSearchParams({ stream: 'true' });
  if (opts.plan) q.set('plan', 'true');
  if (opts.keepalive) q.set('keepalive', 'true');
  if (opts.interval) q.set('interval', String(opts.interval));
  if (opts.model) q.set('model', opts.model);

  const res = await fetch(`${API_URL}/api/v1/chat?${q.toString()}`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json', Accept: 'text/event-stream' },
    body: JSON.stringify({ message, context }),
    signal: opts.signal,
  });
  if (!res.ok || !res.body) throw new Error(`SSE response error: ${res.status}`);

  const reader = res.body.getReader();
  const decoder = new TextDecoder();
  let buffer = '';

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    buffer += decoder.decode(value, { stream: true });

    // Split by double newline between events; keep last partial in buffer
    const events = buffer.split('\n\n');
    buffer = events.pop() ?? '';

    for (const raw of events) {
      // Ignore comment lines (e.g., ": keepalive")
      if (raw.startsWith(':')) continue;

      // Handle multi-line data: take last data: line (simple backend emits single data line per event)
      const dataLine = raw.split('\n').find(l => l.startsWith('data: '));
      if (!dataLine) continue;
      const jsonText = dataLine.slice(6).trim();
      if (!jsonText) continue;

      // Some keepalives are `{}` ‚Äî ignore
      const evt = JSON.parse(jsonText) as ChatStreamEvent;
      if (Object.keys(evt).length === 0) continue;

      yield evt;
      if ((evt as any).done === true) return;
    }
  }
}
```

### Updated Chat Store
```typescript
// stores/chatStore.ts
interface ChatState {
  messages: Message[];
  isLoading: boolean;
  streamingContent: string | null;
  currentToolCall: string | null;
  // ... existing
  
  startStreaming: () => void;
  appendToken: (token: string) => void;
  setToolCall: (toolName: string | null) => void;
  finalizeStream: (fullMessage: Message) => void;
}
```

### Streaming AIMessage
```tsx
// AIMessage.tsx updates
interface AIMessageProps {
  message: Message;
  isStreaming?: boolean;
}

export function AIMessage({ message, isStreaming }: AIMessageProps) {
  return (
    <div className="flex justify-start">
      <div className="max-w-[80%] bg-muted rounded-2xl rounded-tl-sm px-4 py-2">
        <ReactMarkdown>{message.content}</ReactMarkdown>
        {isStreaming && (
          <span className="inline-block w-2 h-4 bg-primary animate-pulse ml-1" />
        )}
        {!isStreaming && message.confidence && (
          <ConfidenceBadge value={message.confidence} />
        )}
      </div>
    </div>
  );
}
```

### Tool Call Indicator
```tsx
// ToolCallIndicator.tsx
export function ToolCallIndicator({ toolName }: { toolName: string }) {
  const toolLabels: Record<string, string> = {
    optimize_price: 'üí∞ Calculating optimal price...',
    explain_decision: 'üîç Analyzing decision factors...',
    sensitivity_analysis: 'üìä Running sensitivity analysis...',
    get_segment: 'üì¶ Identifying segment...',
  };

  return (
    <div className="flex items-center gap-2 text-sm text-muted-foreground py-2">
      <div className="w-4 h-4 border-2 border-primary border-t-transparent rounded-full animate-spin" />
      <span>{toolLabels[toolName] || `üîß Calling ${toolName}...`}</span>
    </div>
  );
}
```

### ChatPanel Streaming Integration
```tsx
// ChatPanel.tsx - streaming flow
const handleSend = async (message: string, plan = false) => {
  addMessage({ role: 'user', content: message });
  startStreaming();
  setToolCall(null);
  const ctrl = new AbortController();
  
  try {
    for await (const event of streamMessage(message, context, {
      plan,
      keepalive: true,
      interval: 15,
      signal: ctrl.signal,
    })) {
      if (event.token) {
        appendToken(event.token);
      }
      if (event.tool_call) {
        setToolCall(event.tool_call);
      }
      if (event.done) {
        finalizeStream({
          role: 'assistant',
          content: event.message,
          confidence: event.confidence,
          toolsUsed: event.tools_used,
        });
      }
    }
  } catch (error) {
    // Handle error, offer retry
  }
};
```

### Orchestrator‚ÄëAware UX (Sub‚ÄëAgents)
- Surface a simple toggle or intent selector to run the orchestrator path:
  - ‚ÄúSimple answer (fast)‚Äù ‚Üí omit `plan`
  - ‚ÄúPlan / Analyze (multi‚Äëstep)‚Äù ‚Üí add `plan=true`
- When `tool_call` arrives, render ToolCallIndicator with a compact label. Do not block token rendering.
- Final event includes `tools_used` array ‚Äî display a small footer (‚ÄúUsed: optimize_price, explain_decision‚Äù).
- If you add route‚Äëlevel hints later (e.g., `node`), they can be shown as subtle step chips (‚Äúpolicy ‚Üí reporter‚Äù).

### Keepalive Handling
- When `keepalive=true` is requested, the backend may send:
  - SSE comment lines: `: keepalive` ‚Üí ignore in parser
  - Empty data events: `{}` ‚Üí ignore (already in code)
- Do not append keepalive to the UI; treat it only as a connection liveness signal.
- If you see no real events for > N seconds even with keepalive, show a small ‚ÄúWorking‚Ä¶‚Äù status but keep the stream open.

### Testing

- Test file: `frontend/tests/unit/chat/streaming.test.ts`
- Mock SSE responses (including keepalive comment lines and empty `{}` events)
- Test token accumulation ‚Üí finalization
- Test tool_call rendering hooks
- Test error recovery fallback

Example (Vitest/Jest)
```ts
// frontend/tests/unit/chat/streaming.test.ts
import { describe, it, expect, vi } from 'vitest';
import { streamMessage } from '@/services/chatService';

const encoder = new TextEncoder();

function makeSSEStream(chunks: string[]): ReadableStream<Uint8Array> {
  return new ReadableStream<Uint8Array>({
    start(controller) {
      for (const c of chunks) controller.enqueue(encoder.encode(c));
      controller.close();
    },
  });
}

describe('streamMessage SSE parsing', () => {
  it('handles tokens, tool_call, keepalive, and final message', async () => {
    const frames = [
      "data: {\"token\": \"The \", \"done\": false}\n\n",
      ": keepalive\n\n",
      "data: {}\n\n", // empty keepalive payload
      "data: {\"tool_call\": \"optimize_price\", \"done\": false}\n\n",
      "data: {\"token\": \"answer\", \"done\": false}\n\n",
      "data: {\"message\": \"Final.\", \"tools_used\": [\"optimize_price\"], \"done\": true}\n\n",
    ];

    // Mock fetch to return our SSE stream
    vi.stubGlobal('fetch', vi.fn(async () => ({
      ok: true,
      body: makeSSEStream(frames),
    }) as unknown as Response));

    const events: any[] = [];
    for await (const evt of streamMessage('q', {
      number_of_riders: 50,
      number_of_drivers: 25,
      location_category: 'Urban',
      customer_loyalty_status: 'Gold',
      number_of_past_rides: 20,
      average_ratings: 4.5,
      time_of_booking: 'Evening',
      vehicle_type: 'Premium',
      expected_ride_duration: 30,
      historical_cost_of_ride: 35.0,
    }, { plan: true, keepalive: true, interval: 15 })) {
      events.push(evt);
    }

    // Should include token and tool_call, and end with done
    expect(events.some(e => e.token === 'The ')).toBe(true);
    expect(events.some(e => e.tool_call === 'optimize_price')).toBe(true);
    const last = events.at(-1);
    expect(last.done).toBe(true);
    expect(last.message).toBe('Final.');
    expect(last.tools_used).toEqual(['optimize_price']);
  });
});
```

## Dependencies

- **Requires Stories 4.9.1 / 4.9.2** (Backend streaming + orchestrator) to be complete. Use `plan=true` for multi‚Äëagent flows.
- Built on top of Story 4.3 (Center Panel Chat) components

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2024-12-02 | 1.0 | Initial story creation - Frontend streaming integration | SM Agent (Bob) |
| 2025-12-03 | 1.1 | Added keepalive handling and orchestrator params (plan/model) | Dev Agent |
| 2025-12-03 | 1.2 | Added FE SSE parser test and usage examples | Dev Agent |

## Usage Examples

- Simple (single‚Äëagent fast path):
```ts
for await (const evt of streamMessage('What is the optimal price?', ctx)) {
  // handle token/tool_call/final
}
```

- Orchestrator plan with model hint and keepalive:
```ts
for await (const evt of streamMessage(
  'Propose a price and summarize for leadership.',
  ctx,
  { plan: true, model: 'gpt-4o-mini', keepalive: true, interval: 15 }
)) {
  // handle events
}
```

## Dev Agent Record

### Agent Model Used
(To be filled by Dev Agent)

### Debug Log References
(To be filled by Dev Agent)

### Completion Notes List
(To be filled by Dev Agent)

### File List
(To be filled by Dev Agent)

## QA Results
(To be filled by QA Agent)
