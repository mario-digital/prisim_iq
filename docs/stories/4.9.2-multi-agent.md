# Story 4.9.2: Multi‑Agent Orchestrator, Policy Gate, and Streaming Enhancements

## Status: Draft

## Assigned To: Mario

## Story

As a pricing analyst stakeholder,
I want a policy‑aware multi‑agent orchestrator with specialized workers,
so that complex pricing requests (optimize → policy check → explain/sensitivity → summarize) are executed reliably with clear reasoning and human approval points, while simple questions remain fast via the existing single agent.

## Acceptance Criteria

1. Orchestrator graph implemented using LangGraph v1 (StateGraph) with the following nodes:
   - router: routes to workers by intent, uses LLM + rules
   - optimizer_worker: calls the existing optimize_price tool/service and returns structured result
   - policy_checker_worker: enforces catalog hierarchy analogs, emits violations + suggested fixes
   - explainer_worker: calls explain_decision and returns SHAP/trace summary text
   - sensitivity_worker: calls sensitivity_analysis and returns confidence band + worst/best
   - reporter_worker: composes a concise analyst summary for leadership (optional, if time)
   - approval_gate: pauses proposals for human sign‑off (resume by thread_id) (optional, if time)
2. Streaming from orchestrator uses LangChain v1’s `astream_events(version="v1")` and maps to the existing SSE pipeline. Token/tool events appear cleanly like the current single‑agent stream.
3. Routing behavior:
   - Simple asks (e.g., “What is the optimal price?”) continue to use the existing single tool‑calling agent path for low latency.
   - Composite asks (e.g., “Propose Q1 updates ensuring hierarchy, then explain drivers”) route to the orchestrator. Also allow explicit opt‑in by `plan=true` query param.
4. Policy checks implement explicit rules:
   - Rideshare analog for catalog hierarchy: New > Exchange > Repair > USM (expressed as price tiers; never violate ordering)
   - Segment/region guardrails (e.g., prevent illogical cross‑tier inversions; configurable thresholds)
   - Emits violations with machine‑readable suggestions (fixes and rationales)
5. Model override (per‑request): optional query param `model` with server‑side allowlist and default. Backend decides final model and logs decision.
6. Health and tools endpoints:
   - `GET /api/v1/chat/health` returns `{status, model, tools_count}`
   - `GET /api/v1/chat/tools` returns list of `{name, description}`
7. SSE keepalive support: optional `keepalive=true&interval=15` to use the provided keepalive generator.
8. Tests cover routing, worker outputs, policy violation detection, and SSE streaming format.

## Tasks / Subtasks

- [ ] Task 1: Orchestrator Module (LangGraph v1)
  - [ ] Create `backend/src/orchestrator/__init__.py` with `build_graph()` factory that compiles the graph (no persistence in v1; add checkpointer optionally if time)
  - [ ] Add `backend/src/orchestrator/state.py` defining a TypedDict (or Pydantic model) `OrchState`:
        - fields: `messages: list[dict]`, `route: str | None`, `plan: list[str] | None`, `violations: list[dict] | None`, `outputs: dict | None`
  - [ ] Add nodes under `backend/src/orchestrator/nodes/`:
        - `router.py` (LLM + simple heuristic rules → returns next route: optimizer | policy | explainer | reporter | end)
        - `optimizer.py` (invokes existing pricing service/tool; returns structured result and short NL summary)
        - `policy.py` (runs policy checks; returns violations + suggested corrections)
        - `explainer.py` (invokes existing explanation; returns short NL summary)
        - `sensitivity.py` (invokes sensitivity analysis; returns band + worst/best and robustness score)
        - `reporter.py` (composes an analyst summary from state.outputs/violations)
        - `approval.py` (optional: raises a pause/signal for human approval)
  - [ ] Wire edges: START → router → conditional to workers → router; workers may forward to `policy` or `reporter`, and finally to END. Keep cycles bounded (max iters or message budget).

- [ ] Task 2: Policy Rules Library
  - [ ] Create `backend/src/policy/rules.py` with pure functions for constraints:
        - `check_hierarchy(prices: dict) -> list[Violation]` (e.g., must satisfy New > Exchange > Repair > USM)
        - `check_tier_thresholds(...)` (optional)
        - `auto_fix_suggestions(violations) -> list[Suggestion]`
  - [ ] Add dataclasses/Pydantic models for `Violation` and `Suggestion`.

- [ ] Task 3: Integration with Chat Flow
  - [ ] Extend `backend/src/agent/agent.py` with a lightweight router decision:
        - If request includes `plan=true` OR the LLM router intent (e.g., contains “propose”, “policy”, “sensitivity + explain”, “executive summary”), invoke orchestrator graph; else use current single‑agent path.
        - Use the same SSE pipeline (`astream_events(version="v1")`) to stream events from the graph.
  - [ ] Ensure session continuity via existing per‑session history; pass `messages` into orchestrator state.

- [ ] Task 4: API Enhancements (Minimal)
  - [ ] `backend/src/api/routers/chat.py` — accept optional:
        - `model: str | None` (query) → validate by allowlist (in settings) and pass as a hint; server decides final
        - `plan: bool = False` (query) → force orchestrator path when True
        - `keepalive: bool = False`, `interval: float = 15.0` → use keepalive generator when enabled
  - [ ] `GET /api/v1/chat/tools` → returns current tool names/descriptions
  - [ ] `GET /api/v1/chat/health` → returns `{ status: "ok", model: <effective>, tools_count, time: ISO }`

- [ ] Task 5: Settings & Guardrails
  - [ ] `backend/src/config.py` — add `openai_model_allowlist: str` (CSV) and a helper `allowed_models()`
  - [ ] Decide final model selection order: admin override > experiment bucket > per‑request hint > task default > global default. Log chosen model and reason.

- [ ] Task 6: Streaming & SSE
  - [ ] Reuse existing SSE mappers; ensure orchestrator events map to token/tool events and final message exactly like the single‑agent path
  - [ ] Keep token cleanup and final message normalization (already implemented) active for orchestrator streams

- [ ] Task 7: Tests
  - [ ] Unit tests for policy rules (hierarchy order; sample violation/fix)
  - [ ] Router intent tests: simple asks → single agent; composite asks → orchestrator
  - [ ] Orchestrator worker tests (optimizer, policy, explainer, reporter)
  - [ ] SSE shape tests: token/tool/final events (golden samples)
  - [ ] Health/tools endpoint tests

## Dev Notes

### Architecture & Patterns
- Use LangGraph v1 `StateGraph` to define the orchestrator. Keep state minimal: `messages`, `route`, `outputs`, `violations`.
- Workers should call existing services/tools directly to avoid nesting agents. Keep prompts role‑specific (short system instructions per worker).
- Keep single‑agent fast path untouched for simple requests.

### LangChain v1 Standards
- Tool‑calling via `langchain_openai.ChatOpenAI`
- Streaming via `astream_events(version="v1")`
- Prompting via `ChatPromptTemplate` or inline worker system prompts (short)
- Avoid deprecated agents/APIs; prefer v1 normalized events and `@tool` functions

### Routing Heuristics (Initial)
- optimizer: contains keywords like “optimal price”, “best price”, “what price”
- policy: “ensure hierarchy”, “check policy”, “violations”, “FAR”, “compliance”
- explainer: “why”, “explain”, “drivers”, “factors”
- plan/report: “propose”, “Q1/Q2 adjustments”, “summary for leadership”, “executive”
- Always honor `plan=true` to force orchestrator

### Policy Examples (Rideshare Analog)
- Hierarchy tier order (conceptual): New > Exchange > Repair > USM
- Disallow inversions: lower tier must not exceed a higher tier for same item/context
- Emit `violations` like:
  - `{"type": "hierarchy_inversion", "item": "<id>", "current": {"new": 100, "repair": 110}, "suggest": {"repair": 95}}`

### Model Override Policy
- Allowlist in settings (e.g., `gpt-4o,gpt-4o-mini`)
- Default to `gpt-4o`
- Log `{hint, chosen, reason}` per request

### SSE Event Serialization (v1 Stream Contract)
- Use a stable envelope aligned with existing `ChatStreamEvent`:
  - `token?: string` — incremental text from model
  - `tool_call?: string` — tool name when a tool starts
  - `message?: string` — final assembled response only at completion
  - `error?: string` — error message on terminal failure (with `done: true`)
  - `done: boolean` — marks completion
- Optional minimal metadata when helpful (final event or occasional meta events):
  - `model?: string` — effective model used for this request (final event only)
  - `thread_id?: string` — session/thread identifier
  - `seq?: number` — monotonically increasing sequence number for ordering
  - `node?: string` — orchestrator node name when emitting meta events
- Do not stream provider metadata blobs; keep payloads small and UI‑friendly.
- If the schema must evolve later, add a top‑level `version: "v1"` field or use a distinct event name.

### Error Serialization
- Final error shape: `{ error: "<message>", done: true, code?: string, retryable?: boolean }`.
- Optionally emit an early error event and then finalize once.

### Heartbeat / Keepalive Design
- Purpose: keep SSE connections alive during slow tool/LLM work.
- When: only if no real events have been sent for `interval` seconds (default 15s). Stop after completion.
- Format (choose one and document):
  - Comment line (preferred, ignored by EventSource): `: keepalive\n\n`
  - Named event: `{ event: "keepalive", data: "{}" }` (client can choose to ignore)
- Do not send empty JSON as a normal data event; avoid triggering UI handlers.

### Additional Endpoints (Design)
- `GET /api/v1/chat/health` → `{ status: "ok", model: <effective>, tools_count: number, time: ISO }`
- `GET /api/v1/chat/tools` → `[{ name, description }]`
- Optional: `GET /api/v1/chat/models` → allowlisted models for per‑request hints
- Optional approvals (if pause/resume added):
  - `POST /api/v1/chat/approve` `{ thread_id, note? }` → resumes paused thread
  - `POST /api/v1/chat/cancel` `{ thread_id }` → cancels paused plan
- Optional policy validation utility: `POST /api/v1/policy/check` → returns violations + suggestions for explicit payloads

### Sequence Numbers
- Add `seq` field to stream events (monotonic int) to help clients reconcile ordering; reset per stream.

## File List (New/Modified)

- New
  - `backend/src/orchestrator/__init__.py` (build_graph)
  - `backend/src/orchestrator/state.py` (OrchState)
  - `backend/src/orchestrator/nodes/router.py`
  - `backend/src/orchestrator/nodes/optimizer.py`
  - `backend/src/orchestrator/nodes/policy.py`
  - `backend/src/orchestrator/nodes/explainer.py`
  - `backend/src/orchestrator/nodes/sensitivity.py`
  - `backend/src/orchestrator/nodes/reporter.py` (optional)
  - `backend/src/orchestrator/nodes/approval.py` (optional)
  - `backend/src/policy/rules.py` (checks + suggestions)

- Modified
  - `backend/src/api/routers/chat.py` (query params: model, plan, keepalive/interval; add `/chat/tools`, `/chat/health`)
  - `backend/src/agent/agent.py` (route decision: orchestrator vs single agent; pass model hint)
  - `backend/src/config.py` (allowlist + helpers)
  - `backend/tests/unit/test_orchestrator/*.py` (new tests)
  - `backend/tests/unit/test_policy/*.py` (new tests)
  - `backend/tests/unit/test_api/test_chat_extras.py` (health/tools)

## OpenAPI Additions (Summary)

- `GET /api/v1/chat/health` → `{status, model, tools_count, time}`
- `GET /api/v1/chat/tools` → `[{name, description}]`
- `POST /api/v1/chat?stream=true&plan=true&keepalive=true&interval=15&model=gpt-4o-mini`
  - Plan routes to orchestrator; keepalive emits heartbeats; model is a hint (allowlist enforced)

## Risks & Mitigations
- Latency: keep single‑agent for simple asks; short worker prompts; bounded graph loops
- Complexity: minimal node set; clear tests; no DB required (no checkpointer unless time)
- Policy ambiguity: start with explicit hierarchy checks; make thresholds configurable in settings

## Demo Script (Guided)
1. Simple ask (single‑agent): “What is the optimal price?” → tokens + answer (< 2s)
2. Composite ask (orchestrator): “Propose Q1 pricing updates ensuring hierarchy; summarize.” → tool calls, policy checks (violations shown), summary, final message
3. Explain path: “Why was that price recommended?” → explainer_worker with SHAP narrative
4. Sensitivity path: “How robust is this recommendation?” → sensitivity_worker with confidence band + worst/best
5. Health/tools: `GET /chat/health` and `GET /chat/tools`
6. Keepalive demo: long run with `keepalive=true` (observe heartbeats until first token)

---

## Definition of Done
- All ACs met; tests pass locally
- SSE stream remains clean (no metadata tokens); final message normalized
- Docs updated: README (new params), API examples, and this story marked complete
